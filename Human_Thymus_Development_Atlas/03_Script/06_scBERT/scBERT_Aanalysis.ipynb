{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ab7bf1a-f040-43fd-b800-0d62712af609",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import transformers\n",
    "import sklearn\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import einops\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "319d406e-5b21-49ab-b434-dda0eb130a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME_DATASET_OUTPUT_PREPROCESS = 'Human_Thymus'\n",
    "\n",
    "# Input path of the reference/raw data\n",
    "PATH_PROJECT = \"/mnt/DOSI/PLATEFORMES/BIOINFORMATIQUE/04_PROJECT/scLLM\"\n",
    "PATH_EXPERIMENT = os.path.join( PATH_PROJECT, \"Human_Thymus_Development_Atlas\")\n",
    "PATH_EXPERIMENT_REFERENCE = os.path.join( PATH_EXPERIMENT, \"01_Reference\")\n",
    "\n",
    "PATH_EXPERIMENT_OUTPUT = os.path.join( PATH_EXPERIMENT, \"05_Output\")\n",
    "ANALYSIS_NAME = os.path.join( PATH_EXPERIMENT_OUTPUT, \"02b_FilterData\") \n",
    "EXTRA_ANALYSIS_NAME = os.path.join(ANALYSIS_NAME, \"Preprocess_Anndata_File_scBERT\")\n",
    "\n",
    "PATH_MODEL = os.path.join( PATH_EXPERIMENT_REFERENCE, \"04_Model\")\n",
    "PATH_MODEL_EXTRA = os.path.join(PATH_MODEL, \"scBERT-master\")\n",
    "MODEL_PATH_SCBERT = os.path.join( PATH_MODEL, \"panglao_pretrain.pth\")\n",
    "PATH_FILE_FINETUNE = os.path.join( PATH_MODEL_EXTRA, \"finetune.py\")\n",
    "PATH_FILE_PREDICT = os.path.join( PATH_MODEL_EXTRA, \"predict.py\")\n",
    "\n",
    "PATH_OUTPUT_SCBERT = os.path.join( PATH_EXPERIMENT_OUTPUT, \"05_scBERT\")\n",
    "os.makedirs(PATH_OUTPUT_SCBERT, exist_ok = True)\n",
    "\n",
    "# Go to workspace to get the finetuned model\n",
    "PATH_WORKSPACE_PROJECT = '/mnt/DOSI/PLATEFORMES/BIOINFORMATIQUE/03_WORKSPACE/thyarion/ciml-cb2mproj/Project/scLLM/'\n",
    "PATH_DATASET_CHOICE = os.path.join(PATH_WORKSPACE_PROJECT, 'Human_Thymus_Development')\n",
    "PATH_SCRIPT = os.path.join(PATH_DATASET_CHOICE, '03_Script')\n",
    "PATH_SCRIPT_EXTRA_SCBERT = os.path.join(PATH_SCRIPT,'05_scBERT')\n",
    "# Il faut changer 06_scBERT qui n'est pas forcément le même nom (en général c'est 05_scBERT)\n",
    "PATH_MODEL_FINETUNED = os.path.join(PATH_SCRIPT_EXTRA_SCBERT, 'ckpts', 'finetune_best.pth')\n",
    "PATH_LABEL = os.path.join(PATH_SCRIPT_EXTRA_SCBERT, 'label')\n",
    "PATH_LABEL_DICT = os.path.join(PATH_SCRIPT_EXTRA_SCBERT, 'label_dict')\n",
    "PATH_CKPTS = os.path.dirname(PATH_MODEL_FINETUNED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d7ce06-2f91-42cb-90bc-b06844b2c473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before start the code, if u encounter a issue (Check if the file \"performer_pytorch\" the gene2vec are correctly pointed to the repertorie who contain the gene2_vec file)\n",
    "\n",
    "for z in range (0,3): # Z is using for count the number of replicat about the number of epoch\n",
    "    for i in range (0, 5) :\n",
    "            # We set the parameter to get the cross fold validation\n",
    "            # Select the file that interest us\n",
    "            VARIABLE_TRAINING_H5AD = os.path.join (EXTRA_ANALYSIS_NAME, NAME_DATASET_OUTPUT_PREPROCESS + '_Training_FOLD_' + str(i) + '_Preprocess.h5ad')\n",
    "            VARIABLE_TEST_H5AD = os.path.join (EXTRA_ANALYSIS_NAME, NAME_DATASET_OUTPUT_PREPROCESS + '_test_FOLD_' + str(i) + '_Preprocess.h5ad')\n",
    "        \n",
    "            # Take the parameter that need for our analysis\n",
    "            dataset_anndata = sc.read_h5ad(VARIABLE_TRAINING_H5AD)\n",
    "            VARIABLE_GENE_NUM = dataset_anndata.n_vars\n",
    "        \n",
    "            # Repertorie and File output with the prediction (You need to add (+ 1 or more) for the repertorie output)\n",
    "            if z == 0 :\n",
    "                VARIABLE_EPOCH = 1\n",
    "                PATH_OUTPUT_EXTRA = os.path.join(PATH_OUTPUT_SCBERT, 'Run_0'+str(z)+'_epoch_'+str(VARIABLE_EPOCH), 'Result_FOLD_'+str(i)+'_epoch_'+str(VARIABLE_EPOCH))\n",
    "            elif z == 1 :\n",
    "                VARIABLE_EPOCH = 5\n",
    "                PATH_OUTPUT_EXTRA = os.path.join(PATH_OUTPUT_SCBERT, 'Run_0'+str(z+2)+'_epoch_'+str(VARIABLE_EPOCH), 'Result_FOLD_'+str(i)+'_epoch_'+str(VARIABLE_EPOCH))\n",
    "            elif z == 2 :\n",
    "                VARIABLE_EPOCH = 10\n",
    "                PATH_OUTPUT_EXTRA = os.path.join(PATH_OUTPUT_SCBERT, 'Run_0'+str(z+4)+'_epoch_'+str(VARIABLE_EPOCH), 'Result_FOLD_'+str(i)+'_epoch_'+str(VARIABLE_EPOCH))\n",
    "            \n",
    "            PATH_OUTPUT_FILE_PREDICTION_SCBERT = os.path.join(PATH_OUTPUT_EXTRA, 'Cell_Type_Predict_FOLD_'+str(i)+'_epoch_'+str(VARIABLE_EPOCH)+'.txt')\n",
    "            os.makedirs(PATH_OUTPUT_EXTRA, exist_ok = True)\n",
    "\n",
    "            PATH_OUTPUT_LABELS = PATH_OUTPUT_EXTRA + '/'\n",
    "            PATH_OUTPUT_LABELS_EXTRA = os.path.join(PATH_OUTPUT_EXTRA, 'ckpts/')\n",
    "            os.makedirs(PATH_OUTPUT_LABELS_EXTRA, exist_ok = True)\n",
    "            \n",
    "            # The command to fine tune scBERT\n",
    "            !python -m torch.distributed.launch {PATH_FILE_FINETUNE} --model_path {MODEL_PATH_SCBERT} --data_path {VARIABLE_TRAINING_H5AD} --gene_num {VARIABLE_GENE_NUM} --epoch {VARIABLE_EPOCH}\n",
    "\n",
    "            # We do the prediction\n",
    "            !python {PATH_FILE_PREDICT} --data_path {VARIABLE_TEST_H5AD} --model_path {PATH_MODEL_FINETUNED} --gene_num {VARIABLE_GENE_NUM} >{PATH_OUTPUT_FILE_PREDICTION_SCBERT}\n",
    "            \n",
    "            # We moove the file to the new repertorie\n",
    "            !cp {PATH_LABEL} {PATH_OUTPUT_LABELS}\n",
    "            !cp {PATH_LABEL_DICT} {PATH_OUTPUT_LABELS}\n",
    "            !cp {PATH_MODEL_FINETUNED} {PATH_OUTPUT_LABELS_EXTRA}\n",
    "            \n",
    "            # We delete every file in the workspace and put it in the new repertorie\n",
    "            !rm {PATH_MODEL_FINETUNED} {PATH_LABEL_DICT} {PATH_LABEL}\n",
    "            !rm -rf {PATH_CKPTS}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
